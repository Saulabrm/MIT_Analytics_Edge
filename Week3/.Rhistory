subset(signatures, id==112273)
phonetic("'saul")
phonetic("saul")
phonetic("t' saul")
blocks[[1]]
blocks[[1]][1]
blocks[1]
blocks[[2]]
blocks[[3]]
blocks[[4]]
blocks[[5]]
blocks[[6]]
blocks[[7]]
blocks[[7]][3]
blocks[[7]][2]
block[[1]][2]
block[[2]][2]
block[[2]][1]
blocks[[2]][1]
blocks[[2]][1,2]
blocks[[2]]
blocks[[1]]
phonetic(c("M Bailara", "Bailara KM"))
-1.5+3*1+5*-.5
log(-1.5+3*1+5*-.5)
exp(-1.5+3*1+5*-.5)
exp(1)
setwd("/Users/saulgarcia/Desktop/Github/MOOCs/MIT Analyticals Edge/Week3")
quality <- read.csv("quality.csv")
str(quality)
table(quality$PoorCare)
install.packages("caTools")
library("caTools")
library(caTools)
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = .75)
split
qualityTrain = subset(quality, split==TRUE)
qualityTest = subset(quality, split==FALSE)
nrow(qualityTrain)
nrow(qualityTest)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
summary(QualityLog)
predictTrain = predict(QualityLog, type="response")
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
predictTrain
QualityLog2 = glm(PoorCare ~ StartedOnCombination + ProviderCount, data = qualityTrain, family= binomial)
summary(QualityLog2)
QualityLog2$coefficients[1]
QualityLog2$coefficients[2]
table(qualityTrain$PoorCare , predictTrain > 0.5)
Sensitivity = 10/ 25
Sensitivity = 10/ (10 +15)
Specificity = 70/ (70+4)
table(qualityTrain$PoorCare , predictTrain > 0.7)
Sensitivity = 8/ (8 +17)
Specificity = 73/ (73+1)
table(qualityTrain$PoorCare , predictTrain > 0.2)
Sensitivity = 16/ (16 +9)  #Increased
Specificity = 54/ (54+20)  #Decreased
=20/25
20/25
15/25
install.packages("ROCR")
library(ROCR)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
ROCRperf = performance(ROCRpred, "tpr","fpr")
plot(ROCRperf)
plot(ROCRperf, colorize = TRUE)
plot(ROCRperf, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1))
plot(ROCRperf, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-.2,1.7))
plot(ROCRperf, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1))
plot(ROCRperf, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-.2,1.7))
predictTest = predict(QualityLog, type="response", newdata=qualityTest)
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
stri_trans_general("Kríshna", Latin-ASCII)
stri_trans_general("Kríshna", "Latin-ASCII")
stri_trans_general("Krïshna", "Latin-ASCII")
head(quality)
test1<-quality[1:6,1:5]
test1
test2<-quality[7:12,1:5]
test2
test1$id = c("a","b","c","d","e")
test1$id = c("a","b","c","d","e","f")
test2$id = c("a","b","c","d","e","a")
test1
test1<- test1[,c(1,6,2,3,4,5)]
test1
test2<- test2[,c(1,6,2,3,4,5)]
test2
dbDisconnect(ucscDb)
dbDisconnect(ucscDb)
ids <- combn(unique(test1$MemberID),2)
ids
ids2 <- combn(unique(test1$id),2)
ids2
ids2 <- combn(unique(test2$id),2)
ids2
unique(test2$id)
sum(unique(test2$id))
as.logical(unique(test2$id))
sum(unique(test1$id))
unique(test1$id)
distinct_(test2$id)
test1$id %>% n()
test1$id %>% distinct = n()
test1$id %>% summarise_()
test1$id %>% summarise_(distinct = n())
test1$id %>% summarise_(n_distinct())
n_distinct(test1$id)
n_distinct(test2$id)
n_distinct(signatures$rowid)
n_distinct(signatures$author)
source('~/.active-rstudio-document')
rm(list=ls())
library(stringr)
library(RMySQL)
library(dplyr)
library(tm)
library(plyr)
drv<- dbDriver("MySQL")
pw<- {"dmkm1234"}
ucscDb <- dbConnect( MySQL(), dbname="dmkm_articles",
host= "127.0.0.1", port=8889,
user="root", password=pw
)
rm(pw)
# Goal: {Author , pub_id(title , author , affliation , co-authors , year, keywords,distance,id,d,)}
articles_data<- dbReadTable(ucscDb,"articles_1")
articles_only<-dbReadTable(ucscDb,"articles")
keywords<- dbReadTable(ucscDb,"articles_keywords_clean_sel")
institution <- dbReadTable(ucscDb, "articles_institutions")
position <- dbReadTable(ucscDb,"articles_authors")
head(position)
head(articles_data)
articles_data<- left_join(articles_data, position)
articles <- dbReadTable(ucscDb, "articles")
head(articles)
articles<- articles_only %>% select(id, title, authors, journal, year)
articles_data<- left_join(position, articles)
head(articles_data)
head(position)
keywords_agg = aggregate(keyword~id, paste , collapse=",", data= keywords)
head(institution)
institution$d3 = paste0(institution$id,",",institution$d1)
institution = aggregate(institution~d3, paste , collapse=",", data= institution)
institution_missing = ldply(strsplit(institution$d3, split =","))
institution_agg = cbind(institution_missing,institution) %>% select(V1, V2 , institution)
names(institution_agg) = c("id", "d", "institution")
institution_agg$id = as.integer(institution_agg$id)
institution_agg$d = as.integer(institution_agg$d)
signature<- left_join(articles_data, keywords_agg)
signature<- left_join(signature,institution_agg)
signature[is.na(signature)]<-''
head(signature)
#Convert authors into co-authors only
coauthors <-str_replace_all(signature$authors, ',', '')
coauthors <- str_replace_all(coauthors, ';', ',')
coauthors <- str_replace_all(coauthors, signature$author, '')
coauthors <- str_replace_all(coauthors,'^, ' , '')
coauthors <- str_replace_all(coauthors,', ,', ',') #and ending comma
coauthors <- str_replace_all(coauthors,', $', '')
signature$authors <- coauthors
names(signature)
names(signature) <- c("id","d", "author","title", "coauthors","journal","year", "keyword", "institution")
dbRemoveTable(ucscDb, "authors_signature")
dbWriteTable(ucscDb, "authors_signature", signature)
dbDisconnect(ucscDb)
library(stringr)
library(RMySQL)
library(dplyr)
library(tm)
library(plyr)
install.packages('stringdist')
library(stringdist)
library(stringi)
rm(list=ls())
drv<- dbDriver("MySQL")
pw<- {"dmkm1234"}
ucscDb <- dbConnect( MySQL(), dbname="dmkm_articles",
host= "127.0.0.1", port=8889,
user="root", password=pw
)
rm(pw)
signatures<- dbReadTable(ucscDb, "authors_signature")
#Step1 - Strip accents from Authors
authors_noaccent <- stri_trans_general(signatures$author,"Latin-ASCII")
#Step2 - Soundex
signatures$phonetic <- as.data.frame(phonetic(authors_noaccent))
#Step3 - Groupping by Phonetics - Blocks
blocks<- split(signatures, signatures$phonetic)
n_distinct(signatures$author)
head(signatures)
unique_id <- rownames(signatures)
unique_id
signatures$unique_id = unique_id
blocks<- split(signatures, signatures$phonetic)
#setwd("/Users/saulgarcia/Desktop/Github/MOOCs/MIT Analyticals Edge/Week3")
quality <- read.csv("quality.csv")
test1<-quality[1:6,1:5]
test2<-quality[7:12,1:5]
test1$id = c("a","b","c","d","e")
test1$id = c("a","b","c","d","e","f")
test2$id = c("a","b","c","d","e","a")
test1<- test1[,c(1,6,2,3,4,5)]
test2<- test2[,c(1,6,2,3,4,5)]
list1 <- list(test1,test2)
list1
ids <- combn(unique(test1$MemberID),1)
ids
ids <- combn(unique(test1$MemberID),2)
ids
ids <- combn(unique(test1$MemberID),3)
ids
# Goal: "id","d", "author","title", "coauthors","journal","year", "keyword", "institution"
ids2 <- combn(unique(test1$id),2)
ids2
ids2 <- combn(unique(test1$id),3)
ids2
ids2 <- combn(unique(test1$id),2)
data.frame(test1[match(ids2[1,], test1$ID), ], test1[match(ids2[2,], test1$ID), ])
data.frame(test1[match(ids2[1,], test1$id), ], test1[match(ids2[2,], test1$id), ])
unique(test1$id)
unique(list1$id)
unique(list1[][id])
unique(list1[]["id"])
unique(list1[1]["id"])
unique(list1[[1]["id"])
list1[[1]]
list1[[1]]$id
unique(list1[[1]]$id)
lapply(list1, function(x) combn(unique(list[[x]]$id)))
lapply(list1, combn(unique(list[[]]$id)))
lapply(list1, function(x) combn(unique(list1[[x]]$id)))
list1$id
list1[[1:2]]
list1[[1]]
list1[1
]
list1[1:2]
list1[1:2]$id
list1[1:2][2]
list1[1:2]
list1[1:2][2]
list1[1:2][,2]
list1[1:2][[2]]
list1[1:2][[[2]]]
combn(unique(test1$id),2)
combn(unique(test2$id),2)
test1
ids2 <- combn(unique(test1$id),2)
data.frame(test1[match(ids2[1,], test1$id), ], test1[match(ids2[2,], test1$id), ])
list1
list[1]$id
list[[1]$id
list1[[1]$id
list1[1]$id
list1[[1]]$id
list1[[2]]$id
list1[[1:2]]$id
list1[[c(1,2)]]$id
lapply(list1, function(x) combn(unique(x$id),2))
data.frame(test1[match(ids2[1,], test1$id), ], test1[match(ids2[2,], test1$id), ])
lapply(list1, function(x) combn(unique(x$id),2))
lapply(list1, function(x) b<-combn(unique(x$id),2))
s
lapply(list1, function(x) b<-combn(unique(x$id),2))
lapply(list1, function(x) combn(unique(x$id),2))
lapply(list1, function(x) data.frame(x[match(combn(unique(x$id),2)[1,], x$id), ], x[match(combn(unique(x$id),2)[2,], x$id), ]))
blocks[[1]]
blocks_paired<-lapply(blocks, function(x) data.frame(x[match(combn(unique(x$unique_id),2)[1,], x$unique_id), ], x[match(combn(unique(x$unique_id),2)[2,], x$unique_id), ]))
blocks_paired<-lapply(blocks[[1]], function(x) data.frame(x[match(combn(unique(x$unique_id),2)[1,], x$unique_id), ], x[match(combn(unique(x$unique_id),2)[2,], x$unique_id), ]))
lapply(list1, function(x) data.frame(x[match(combn(unique(x$id),2)[1,], x$id), ], x[match(combn(unique(x$id),2)[2,], x$id), ]))
list1
lapply(blocks, function(x) data.frame(x[match(combn(unique(x$id),2)[1,], x$id), ], x[match(combn(unique(x$id),2)[2,], x$id), ]))
#setwd("/Users/saulgarcia/Desktop/Github/MOOCs/MIT Analyticals Edge/Week3")
framingham = read.csv("framingham.csv")
str(framingham)
library(caTools)
set.seed(100)
set.seed(1000)
split = sample.split(quality$TenYearCHD, SplitRatio = 0.65)  #Splits intellegently
split = sample.split(quality$framinghamCHD, SplitRatio = 0.65)  #Splits intellegently
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.65)  #Splits intellegently
train=subset(framingham, split==TRUE)
test = subset(framingham, split==FALSE)
framinghamLog = glm(TenYearCHD ~ ., data = train, family = binomial )#By using "." it uses all of the features as ind. var.
summary(framinghamLog)
predictTest = predict(framinghamLog, type="response", newdata = test)
table(test$TenYearCHD, predictTest > 0.5)
sum(table(test$TenYearCHD, predictTest > 0.5))
Accuracy = (1069+11)/sum(table(test$TenYearCHD, predictTest > 0.5))
Accuracy
Baseline = (1069 + 6)/sum(table(test$TenYearCHD, predictTest > 0.5))
Baseline
library(ROCR)
ROCRpred = prediction(predictTest, test$TenYearCHD)
ROCRpred
as.numeric(performance(ROCRpred,"auc")@y.values)
cm = sum(table(test$TenYearCHD, predictTest > 0.5))
TN = cm[1,1]
cm
cm = table(test$TenYearCHD, predictTest > 0.5)
TN = cm[1,1]
TN
TP = cm[2,2]
TN = cm[1,1]
TP = cm[2,2]
FN = cm[1,2]
FP = cm[2.1]
cm = table(test$TenYearCHD, predictTest > 0.5)
cm
Sensitivity =  TP/(TP+FN)
Specificity =  TN/(TN + FP)
Sensitivity
Specificity
FN = cm[2,1]
FP = cm[1.2]
Sensitivity =  TP/(TP+FN)
Specificity =  TN/(TN + FP)
Sensitivity
Specificity
cm = table(test$TenYearCHD, predictTest > 0.5)
TN = cm[1,1]
TP = cm[2,2]
FN = cm[2,1]
FP = cm[1.2]
Sensitivity =  TP/(TP+FN)
Specificity =  TN/(TN + FP)
Sensitivity
Specificity
cm = table(test$TenYearCHD, predictTest > 0.5)
TN = cm[1,1]
TP = cm[2,2]
FN = cm[2,1]
FP = cm[1.2]
Accuracy = (1069+11)/sum(table(test$TenYearCHD, predictTest > 0.5))
Accuracy
Baseline = (1069 + 6)/sum(table(test$TenYearCHD, predictTest > 0.5))
ROCRpred = prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred,"auc")@y.values)
#[1] 0.7421095 Which means that the model can differentiate between low risk patients and high risk patients pretty well.
Sensitivity =  TP/(TP+FN)
Specificity =  TN/(TN + FP)
cm
FN
11/(11+187)
FP = cm[1,2]
Sensitivity =  TP/(TP+FN)
Specificity =  TN/(TN + FP)
Sensitivity
Specificity
polling = read.csv("PollingData.csv")
str(polling)
table(polling$Year)
summary(polling)
install.packages("mice")
library(mice)
simple = polling[c("Rasmussen" ,"SurveyUSA","PropR", "DiffCount")]
summary(simple)
set.seed(144)
imputed = complete(simple)
imputed = complete(mice(simple))
summary(imputed)
polling$Rasmussen = imputed$Rasmussen
polling$SurveyUSA = imputed$SurveyUSA
summary(polling )
Train = subset(polling,  Year ==2004 | Year ==  2008)
Test = subset(polling, Year==2012)
table(Train$Republican)
Baseline = table(Train$Republican)[2]/sum(table(Train$Republican)[2])
Baseline = table(Train$Republican)[2]/sum(table(Train$Republican))
Baseline
sign(-10)
table(sign(Train$Rasmussen))
Train$Rasmussen
table(Train$Republican , sign(Train$Rasmussen))
cor(Train)
cor(Train[c(c("Rasmussen" ,"SurveyUSA","PropR", "DiffCount","Republican"))])
mod1 =glm(Republican ~PropR, data=Train, family=binomial)
summary(mod1)
pred1 = predict(mod1, type="response")
table(Train$Republican, pred1 >=.5)
mod2 =glm(Republican ~ SurveyUSA + DiffCount, data=Train, family=binomial)
pred2 = predict(mod2, type="response")
table(Train$Republican, pred2 >=.5)
summary(mod2)
table(Test$Republican, sign(Test$Rasmussen))
TestPrediction = predict(mod2, newdata = Test, type="response")
table(Test$Republican, TestPrediction >=.5)
subset(Test, TestPrediction >= 0.5 & Republican ==0)
attempt<-lapply(blocks, function(x) combn(unique(x$unique_id),2))
Q
attempt<-lapply(blocks, function(x) combn(unique(x$id),2))
Q
Q
Q
Q
Q
L <- list(a = 1:4, b = 4:1) # test input
n <- length(L[[1]])
DF <- structure(L, row.names = c(NA, -n), class = "data.frame")
L
n
DF
ids <- combn(unique(signatures$uniqueid),2)
ids <- combn(unique(signatures$id),2)
names(signatures)
test1
ids2
data.frame(test1[match(ids2[1,], test1$id), ], test1[match(ids2[2,], test1$id), ])
list1
lapply(list1, function(x) combn(unique(x$id),2))
lapply(blocks, function(x) data.frame(x[match(combn(unique(x$id),2)[1,], x$id), ], x[match(combn(unique(x$id),2)[2,], x$id), ]))
Q
Q
Q
Q
Q
Q
Q
setwd("/Users/saulgarcia/Desktop/Github/MOOCs/MIT Analyticals Edge/Week3")
baseball <- read.csv("baseball.csv")
table<-(baseball$Team, baseball$League)
table(baseball$Team, baseball$League)
table(baseball$Team, baseball$Year)
str(baseball)
nrow(baseball)
table(baseball$Year)
baseball <- subset(baseball, Playoffs == 1)
dim(baseball)
nrow(baseball)
table(baseball$Playoffs, baseball$Team)
table( baseball$Team, baseball$Playoffs)
table(baseball$Year)
PlayoffTable= table(baseball$Year)
names(PlayoffTable)
str(names(PlayoffTable))
PlayoffTable[c("1990", "2001")]
source('~/.active-rstudio-document')
str(baseball)
PlayoffTable[baseball$Year]
baseball$NumCompetitors = PlayoffTable[as.character(baseball$Year)]
str(baseball)
PlayoffTable
subset(baseball, NumCompetitors == 8)
dim(subset(baseball, NumCompetitors == 8))
head(baseball$RankPlayoffs)
baseball$WorldSeries = as.numeric(baseball$RankPlayoffs == 1)
table(baseball$WorldSeries)
table(baseball$WorldSeries)[1]
LogReg<-c("Year",  "RS",  "RA", "W", "OBP", "SLG", "BA",  "RankSeason", "OOBP","OSLG" , "NumCompetitors", "League")
Fit1<- glm(WorldSeries ~ LogReg[1] , data=baseball, family=binomial)
LogReg[1]
Fit1<- glm(WorldSeries ~ Year , data=baseball, family=binomial)
LogReg<-c(Year,  "RS",  "RA", "W", "OBP", "SLG", "BA",  "RankSeason", "OOBP","OSLG" , "NumCompetitors", "League")
LogReg<-c("Year",  "RS",  "RA", "W", "OBP", "SLG", "BA",  "RankSeason", "OOBP","OSLG" , "NumCompetitors", "League")
Fit1<- glm(WorldSeries ~ LogReg , data=baseball, family=binomial)
Fit1<- glm(WorldSeries ~ LogReg[1] , data=baseball, family=binomial)
LogReg[1]
LogReg[1]
Fit1<- glm(WorldSeries ~ LogReg[1] , data=baseball, family=binomial)
glm(WorldSeries ~ LogReg[1] , data=baseball, family=binomial)
Fit1<- glm(WorldSeries ~ Year , data=baseball, family=binomial)
summary(Year)
summary(Fit1)
Fit2<- glm(WorldSeries ~ RS , data=baseball, family=binomial)
summary(Fit2)
Fit2<- glm(WorldSeries ~ RA , data=baseball, family=binomial)
summary(Fit2)
Fit3<- glm(WorldSeries ~ W , data=baseball, family=binomial)
summary(Fit3)
Fit3<- glm(WorldSeries ~ OBP , data=baseball, family=binomial)
summary(Fit3)
Fit3<- glm(WorldSeries ~ SLG , data=baseball, family=binomial)
summary(Fit3)
Fit3<- glm(WorldSeries ~ BA , data=baseball, family=binomial)
summary(Fit3)
Fit3<- glm(WorldSeries ~ RankSeason , data=baseball, family=binomial)
summary(Fit3)
Fit5<- glm(WorldSeries ~ Year + RA + RankSeason + NumCompetitors, data = baseball, family = binomial)
summary(Fit5)
cor(baseball[c("Year","RA","RankSeason","NumCompetitors")])
Fit1<- glm(WorldSeries ~ Year , data=baseball, family=binomial)
summary(Fit1)
Fit2<- glm(WorldSeries ~ RA , data=baseball, family=binomial)
summary(Fit2)
Fit3<- glm(WorldSeries ~ RankSeason , data=baseball, family=binomial)
summary(Fit3)
Fit4<- glm(WorldSeries ~ NumCompetitors , data=baseball, family=binomial)
summary(Fit4)
Fit5<- glm(WorldSeries ~ Year + RA, data = baseball, family = binomial)
summary(Fit5)
Fit6<- glm(WorldSeries ~ Year + RankSeason, data = baseball, family = binomial)
summary(Fit6)
Fit7<- glm(WorldSeries ~ RankSeason + NumCompetitors, data = baseball, family = binomial)
summary(Fit7)
Fit8<- glm(WorldSeries ~ Year + NumCompetitors, data = baseball, family = binomial)
summary(Fit8)
Fit9<- glm(WorldSeries ~ RA + RankSeason, data = baseball, family = binomial)
summary(Fit9)
Fit10<- glm(WorldSeries ~ RA + NumCompetitors, data = baseball, family = binomial)
summary(Fit10)
summary(glm(WorldSeries ~ RA + NumCompetitors, data = baseball, family = binomial)
summary(Fit10))
summary(glm(WorldSeries ~ RA + NumCompetitors, data = baseball, family = binomial))
summary(glm(WorldSeries ~ RA + NumCompetitors, data = baseball, family = binomial))
